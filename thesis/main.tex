% options:
% thesis=B bachelor's thesis
% thesis=M master's thesis
% czech thesis in Czech language
% slovak thesis in Slovak language
% english thesis in English language
% hidelinks remove colour boxes around hyperlinks


\documentclass[thesis=B,czech]{FITthesis}[2012/06/26]

\usepackage[utf8]{inputenc} % LaTeX source encoded as UTF-8

\usepackage{graphicx} %graphics files inclusion
% \usepackage{amsmath} %advanced maths
% \usepackage{amssymb} %additional math symbols

\usepackage{dirtree} %directory tree visualisation



% % list of acronyms
% \usepackage[acronym,nonumberlist,toc,numberedsection=autolabel]{glossaries}
% \iflanguage{czech}{\renewcommand*{\acronymname}{Seznam pou{\v z}it{\' y}ch zkratek}}{}
% \makeglossaries

\newcommand{\tg}{\mathop{\mathrm{tg}}} %cesky tangens
\newcommand{\cotg}{\mathop{\mathrm{cotg}}} %cesky cotangens

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 
% ODTUD DAL VSE ZMENTE
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % 

\department{Katedra softwarového inženýrství}
\title{Systém pro analýzu proudu dat v reálném čase}
\authorGN{David} %(křestní) jméno (jména) autora
\authorFN{Viktora} %příjmení autora
\authorWithDegrees{David Viktora} %jméno autora včetně současných akademických titulů
\supervisor{Ing. Adam Šenk}
\acknowledgements{Poděkování ....}
\abstractCS{V~několika větách shrňte obsah a přínos této práce v~češtině. Po přečtení abstraktu by se čtenář měl mít čtenář dost informací pro rozhodnutí, zda chce Vaši práci číst.}
\abstractEN{Sem doplňte ekvivalent abstraktu Vaší práce v~angličtině.}
\placeForDeclarationOfAuthenticity{V~Praze}
\declarationOfAuthenticityOption{4} %volba Prohlášení (číslo 1-6)
\keywordsCS{Nahraďte seznamem klíčových slov v češtině oddělených čárkou.}
\keywordsEN{Nahraďte seznamem klíčových slov v angličtině oddělených čárkou.}


\begin{document}

% \newacronym{CVUT}{{\v C}VUT}{{\v C}esk{\' e} vysok{\' e} u{\v c}en{\' i} technick{\' e} v Praze}
% \newacronym{FIT}{FIT}{Fakulta informa{\v c}n{\' i}ch technologi{\' i}}

\begin{introduction}
	Kratce o jednotlivých bodech zadání a struktuře prace, motivace
	
\end{introduction}

%\chapter
%\section
%\subsection
%


\chapter{Situace v oblasti zpracovávání dat ??}
	V současné době generujeme obrovská množství dat - podle některých odhadů to například v roce 2012 mohlo být až 2,5 exabajtů za den\cite{bbc-bigdata}. Od té doby se rychlost přibývání dat stále zvyšuje. Například nárůst objemu dat dostupných na internetu je způsoben jeho neustále větším rozšířením a rostoucí dostupností. V  roce 2016 je k němu připojeno již přes 3,3 miliardy obyvatel planety\cite{internet-live-stats}, což je téměř polovina všech. Roste také míra využívání internetu. Oproti dřívějšku na internetu trávíme nejen díky chytrým telefonům stále více času a využíváme například sociální sítě, internetové vyhledávání a další online služby. Během toho jsou nám zobrazována personalizovaná data a cílené reklamní nabídky. Také ve firemní i státní sféře výrazně roste stupeň využívání informačních technologií a v návaznosti na to objem produkovaných dat. S přibývajícími daty nastávají problémy s jejich zpracováním. Jedním z nich je schopnost zpracovat tak veliké objemy dat, druhým je schpnost jejich zpracování v dostatečně krátkém, ideálně reálném čase. Často je přitom potřeba vyřešit oba tyto problémy naráz. 
		 
\section{Streamové zpracování dat}	
	....


\section{Zpracování velkých objemů dat}
	Při práci s velkými objemy dat se klasické technologie používané v minulosti stále častěji ukazují jako nedostatečně rychlé nebo obecně neschopné tato data zpracovat. Je proto nutné sáhnout po nových technologiích určených pro práci s nimi. Touto problematikou obecně se zabývá relativně nový a často skloňovaný obor Big Data. Bez technologií pro Big Data se v dnešní době neobejdou třeba již zmiňované internetové vyhledávače nebo sociální sítě, využití ale nacházejí i v mnoha dalších oblastech. Jejich rozvoj je také předpokladem například pro další rozšíření tzv. Internet of Things\cite{bigdata-iot}.  

	Obecně můžeme říci, že o Big Datech hovoříme v případech, kdy je potřeba zpracovávat objemy dat v řádech gigabajtů a více. To je ale velice zjednodušený popis tohoto termínu - přesná definice však neexistuje a na celý problém se dá dívat různými způsoby. Rozšířené je například také tvrzení říkající, že o Big Datech mluvíme zkrátka v těch případech, kdy klasické databázové a softwarové nástroje kvůli objemu těchto dat selhávají\cite{webopedia-bigdata}. 

	Přestože jednotná definice neexistuje, ustálilo se několik problémů, kterým je při práci s Big Daty potřeba čelit. Jedná se o takzvaná 3+1V - Volume, Velocity, Variety a později přidaná vlastnost Veracity\cite{dp-customer-inteligence}. Volume popisuje objem zpracovávaných dat, Velocity pak rychlost, jakou data přibývají. Charakteristikou Variety popisujeme různorodost dat a Veracity určuje úplnost a míru důvěryhodnosti dat. Ne vždy se setkáme se všemi těmito problémy naráz, každá z nich ale přidává na složitosti zpracování těchto dat. 
	
 Technologie pro Big Data je samozřejmě možné použít jak na data strukturovaná, tak především na ta nestrukturovaná. Jelikož ta nestruktorovaná přibývají výrazně rychleji než ta strukturovaná\cite{structured-unstructured}, a protože je jejich zpracování často výpočetně náročnější, jsou právě technologie pro Big Data vhodnou volbou. Klasickým příkladem nestrukturovaných dat je lidská řeč v psané formě - ta rozhodně obsahuje spoustu informací, ale ve formě kterou je počítačově složité analyzovat. Jako příklad takových dat můžeme uvést právě příspěvky na sociální síti Twitter, které se částečně věnuje i tato práce. 
 
 	Právě analýzou lidské řeči se zabývá obor zvaný Natural Langugage Processing, obecně vytěžováním znalostí z dat pak tzv. Data Mining. Technikami spadajícími do těchto oborů je možné získat opravdu cenné informace. Například analýzou dat pohybu uživatele po webové stránce a jeho chováním můžeme odhalit nedostatky tohoto webu a jejich odstraněním zvýšit míru konverze. Hovoříme-li v kontextu sociální sítě Twitter, možnosti jsou ještě zajímavější. Na základěji příspěvků a vyplněných informací jednotlivých uživatelů můžeme například odhadovat jejich volební preference nebo nabízet velice přesně cílenou reklamu. Konkrétnějším příkladem může být zajímavý projekt ze Stanfordské univerzity usilující o odhad vývoje cen akcií na základě analýzy sentimentu příspěvků z Twitteru\cite{stock-stanford}. Touto technikou se budu zabývat v následující kapitole této práce.  
	
	Jedny z prvních konkrétních technologií pro práci s Big Daty vznikaly na přelomu tisíciletí ve společnosti Google. Právě Google v roce 2004 zveřejnil článek o modelu MapReduce\cite{mapreduce-google}, která se stala stavebním kamenem pro většinu dalších technologií pro práci s velkými objemy dat. MapReduce vlastně popisuje dvě nezávislé funkce. První z nich je funkce Map, ve které jsou ze vstupních dat vygenerovány dvojice klíč a hodnota. Poté co je funkce Map dokončena, její výstup je použit jako vstup do funkce Reduce. Ta pak spojí vstupní data podle klíče\cite{mapreduce-description}. Klíčovou vlastností MapReduce modelu je možnost paralelizace Map fáze na počítačovém clusteru. Jeden z počítačů v clusteru například přijme požadavek od uživatele. Tento počítač náhodně rozdělí vstupní data všem počítačům v clusteru a vyčká na provedení Map fáze jednotlivými počítači. Výsledná data pak sám master spojí v Reduce fázi a navrátí výsledek uživateli. Obecně distribuce co největšího množství operací a výpočtů po počítačovém clusteru je hlavním principem fungování technologií pro zpracování velkých objemů dat. 
	
	Konkrétních frameworků pro zpracování Big Dat je několik, tím klíčovým je ale bezesporu open-source framework Hadoop, jehož první plná verze vyšla na konci roku 2011, ale byl využíván již přibližně od roku 2006 například ve společnosti Yahoo\cite{???}. Je určen pro použití na počítačových clusterech složeným z řádově desítek až stovek relativně levných serverů. Hadoop se skládá ze tří hlavních komponent - Hadoop Distributed File System, Hadoop MapReduce a Hadoop YARN. HDFS neboli Hadoop Distributed File System je distribuovaný filesystem zajišťující rozprostření dat po jednotlivých počítačích v clusteru. Klade důraz na toleranci výpadků částí clusteru. Pro zabránění ztráty dat v případě takového výpadku dochází mimo jiné k jejich replikaci na více strojů. Hadoop MapReduce je konkrétní implementace MapReduce modelu zmiňovaného dříve. Hadoop YARN pak slouží především k řízení zdrojů v clusteru, tedy například rozdělování práce jednotlivým serverům v clusteru. Nevýhodou Hadoopu je fakt, že nepodporuje proudové zpracování dat, ale pouze zpracování batchové. 


\section{Streamové zpracování velkých objemů dat}
	V praxi však často potřebujeme velké objemy dat zpracovávat v co nejkratším čase. Technologií umožňujících streamové zpracování velkých objemů dat je několik, ty nejzajímavější jsou ale Apache Spark, Apache Storm a Apache Flink. Každá z těchto technologií funguje na trochu jiném principu a je vhodná pro jiné využití. 
	
	První ze zmiňovaných, Apache Spark, kterým se tato práce zabývá, je zaměřený především na batchové zpracování dat. Jedna z jeho komponent nabízí i možnost zpracování proudů dat, narozdíl od zbývajících dvou však nejde o plnohodnodtné proudové zpracování, ale o takzvané micro-batchové zpracování. Spark nereaguje na každý nový datový objekt samostatně, ale nejdříve data po zadanou dobu střádá a poté je víceméně klasicky batchově zpracuje\cite{??}. Přestože Spark při zpracování proudů dat obvykle nedosahuje takových rychlostí jako zbylé dvě technologie, i s ním je možné dosáhnout zpracování dat v téměř reálném čase\cite{https://yahooeng.tumblr.com/post/135321837876/benchmarking-streaming-computation-engines-at}. Spark je oproti zbylým dvěma projektům v pozdější fázi vývoje a je v rámci Apache Software Foundation nejaktivněji vyvýjeným projektem\cite{??}. 
	
	Apache Flink v relativně velké míře konkuruje Sparku. Podporuje oba způsoby zpracování dat, primárně je ale zaměřený na streamy. Jak již bylo řečeno, narozdíl od Sparku se jedná o streamové zpracování v pravém slova smyslu a je v něm tak možné dosahovat kratších dob zpracování dat. I právě proto se předpokládá, že v oblasti zpracování proudů dat v budoucnu předstihne Spark\cite{http://www.kdnuggets.com/2015/11/fast-big-data-apache-flink-spark-streaming.html}. Jeho další výhodou je například možnost využití existujících programů pro Storm či MapReduce. 
	
	Apache Storm jako jediný ze zmiňovaných frameworků nabízí pouze streamové zpracování, i on poskytuje pravé streamové zpracování. Jeho API je oproti Flinku více nízkoúrovňové a vývoj v něm tak může být pracnější. Obecně ale funguje na podobném principu jako právě Flink. Oproti zbývajícím dvěma technologiím Storm postrádá například tzv. Streaming Windows a další funkce\cite{http://stackoverflow.com/questions/30699119/what-is-are-the-main-differences-between-flink-and-storm}.
	
	Obecně se tedy v kontextu streamového zpracování Spark hodí pro ty případy užití, kdy není nutné co nejrychlejší zpracování a řádově několikasekundové zpoždění nehraje roli. Je pak momentálně oproti zbylým technologiím vhodnou volbou díky svojí vyspělosti a jednoduchosti. Pokud je nutné opravdu real-time zpracování, je třeba volit mezi Flinkem a Stormem. Ty fungují na podobném principu, nicméně Flink má některé funkcionality, které ve Stormu chybí. Nabízí vysokoúrovňové API a do budoucna se jeví jako perspektivnější framework. 
	
	
	
\section{Apache Spark}
	Apache Spark je relativně novou technologií. Navazuje na již zmiňovaný Hadoop a může používat některé jeho komponenty, ... . 

%\section{Způsoby zpracování velkých objemů dat}
%	Batchové/streamové, proc se v mem pripade hodi streamove




\chapter{Analýza}
\section{Metody pro analýzu textu}
	Sentiment, ...

\section{Požadavky na systém}
	Funkční a nefunkční (co konkretne merit?, ...)

\section{Dostupné technologie}
	- dostupne technologie

\section{Twitter streaming API}
	Jak vypada API, tweet, ze API nenabizi vsechny prispevky - gnip.com

\chapter{Návrh}
\section{Celkový pohled na systém}
	jednotlive casti, propojeni, diagram 
\section{Analýza tweetů}
	jak bude vypadat program ve sparku
\section{Struktura databáze}
	schema, ...
\section{Návrh API}
	definice endpointů atd.

\chapter{Implementace}
\section{Použité technologie}
\subsection{Analýza proudu dat}
\subsection{Databáze}
\subsection{API webserver}
\subsection{Webová aplikace}

\chapter{Testování}
\section{Test API endpointů}
	da se web castecne povazovat jako otestovani api?
\section{???}

\chapter{Nasazení}

\chapter{Zhodnocení výsledků}



\begin{conclusion}
	Zaver
\end{conclusion}



\begin{thebibliography}{1}

\bibitem{bbc-bigdata} WALL, Matthew. Big Data: Are you ready for blast-off? In: BBC News [online]. 2014 [cit. 2016-04-10]. Dostupné z: http://www.bbc.com/news/business-26383058

\bibitem{internet-live-stats} Internet Users. Internet Live Stats: Internet Usage \& Social Media Statistics [online]. [cit. 2016-04-10]. Dostupné z: http://www.internetlivestats.com/internet-users/

\bibitem{bigdata-iot} Why Big Data And The Internet of Things Are A Perfect Match. In: Datamation: IT Management, IT Salary, Cloud Computing, Open Source, Virtualization, Apps. [online]. [cit. 2016-04-10]. Dostupné z: http://www.datamation.com/applications/why-big-data-and-the-internet-of-things-are-a-perfect-match.html

\bibitem{webopedia-bigdata} What is big data? Webopedia: Online Tech Dictionary for IT Professionals [online]. [cit. 2016-04-11]. Dostupné z: http://www.webopedia.com/TERM/B/big\_data.html

\bibitem{dp-customer-inteligence} TŘÍSKA, Martin. Customer Intelligence v kontextu Big Data. Praha, 2013. Diplomová práce. České vysoké učení technické v Praze. Vedoucí práce Tomáš Bruckner.

\bibitem{structured-unstructured}Structured vs. Unstructured Data: The Rise of Data Anarchy. In: Data Science Central [online]. [cit. 2016-04-11]. Dostupné z: http://www.datasciencecentral.com/profiles/blogs/structured-vs-unstructured-data-the-rise-of-data-anarchy

\bibitem{stock-stanford}MITTAL, Anshul a Arpit GOEL. Stock Prediction Using Twitter Sentiment Analysis. 2012. Dostupné také z: http://cs229.stanford.edu/proj2011/GoelMittal-StockMarketPredictionUsingTwitterSentimentAnalysis.pdf. Standford University.

\bibitem{mapreduce-google}DEAN, Jeffrey a Sanjay GHEMAWAT. MapReduce: simplified data processing on large clusters. Google Inc., 2004.

\bibitem{mapreduce-description}What is MapReduce. IBM [online]. [cit. 2016-04-11]. Dostupné z: https://www-01.ibm.com/software/data/infosphere/hadoop/mapreduce/


  
\end{thebibliography}



\appendix

\chapter{Seznam použitých zkratek}
% \printglossaries
\begin{description}
	\item[Item1] foo
	\item[Item2] bar
\end{description}

\chapter{Obsah přiloženého CD}

%upravte podle skutecnosti

\begin{figure}
	\dirtree{%
		.1 readme.txt\DTcomment{stručný popis obsahu CD}.
		.1 exe\DTcomment{adresář se spustitelnou formou implementace}.
		.1 src.
		.2 impl\DTcomment{zdrojové kódy implementace}.
		.2 thesis\DTcomment{zdrojová forma práce ve formátu \LaTeX{}}.
		.1 text\DTcomment{text práce}.
		.2 thesis.pdf\DTcomment{text práce ve formátu PDF}.
		.2 thesis.ps\DTcomment{text práce ve formátu PS}.
	}
\end{figure}

\end{document}

\iffalse
\fi